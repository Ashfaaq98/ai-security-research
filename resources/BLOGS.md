# BLOGS & ARTICLES — AI Security & Red Teaming (Chronological)

Curated practitioner-focused posts, vendor writeups, tutorials and analysis relevant to AI red teaming and agent security. Sorted newest → oldest (grouped by year). Keep short — title, source, URL.

---

## 2025
- **New attack can steal cryptocurrency by planting false memories in AI chatbots** — Ars Technica — May 2025  
  https://arstechnica.com/security/2025/05/ai-agents-that-autonomously-trade-cryptocurrency-arent-ready-for-prime-time/

- **The 2025 AI Threat Horizon: Securing the Agentic Enterprise** — LinkedIn / Philip A. Dursey — 2025  
  https://www.linkedin.com/pulse/2025-ai-threat-horizon-securing-agentic-enterprise-philip-a-dursey-usdhc/

- **Agentic AI Threat Modeling Framework: MAESTRO** — Cloud Security Alliance blog — 2025  
  https://cloudsecurityalliance.org/blog/2025/02/06/agentic-ai-threat-modeling-framework-maestro

---

## 2024 – 2023 (selected)
- **Poison everywhere: No output from your MCP server is safe** — CyberArk (analysis/POC) — 2024  
  https://www.cyberark.com/resources/threat-research-blog/poison-everywhere-no-output-from-your-mcp-server-is-safe

- **Simulating a Context-Poisoning Vulnerable MCP Server: A POC** — Backslash Security — (blog/POC)  
  https://www.backslash.security/blog/simulating-a-vulnerable-mcp-server-for-context-poisoning

- **Lilian Weng — Adversarial Attacks on LLMs** — Long-form blog / primer — 2023  
  https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/

- **PromptFoo — Jailbreaking LLMs (guide)** — practical walkthrough — (date varies)  
  https://www.promptfoo.dev/blog/how-to-jailbreak-llms/

- **Pillar Security — LLM Backdoors at the Inference Level** — blog analysis — (date varies)  
  https://www.pillar.security/blog/llm-backdoors-at-the-inference-level-the-threat-of-poisoned-templates

- **Unit42 — Agentic AI Threats (Unit42 research blog)** — 2024/2025 coverage  
  https://unit42.paloaltonetworks.com/agentic-ai-threats/

---

## Vendor & Official Guidance
- **Microsoft: Planning red teaming for LLMs** — Microsoft Learn documentation (guidance & methodology)  
  https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming

- **Meta: LlamaFirewall — guardrail system (blog / paper)** — Meta research pages  
  https://ai.meta.com/research/publications/llamafirewall-an-open-source-guardrail-system-for-building-secure-ai-agents/

- **Google: Secure AI Framework (SAIF)** — high-level guidance & principles  
  https://safety.google/cybersecurity-advancements/saif/

- **SANS: Securing AI in 2025 — risk-based approach** — practical risk guidance (blog)  
  https://www.sans.org/blog/securing-ai-in-2025-a-risk-based-approach-to-ai-controls-and-governance/

---

## Opinion / Analysis / Misc
- **How to Hack AI Agents and Applications** — Joseph Thacker — practical analysis & walkthroughs (2025)  
  https://josephthacker.com/hacking/2025/02/25/how-to-hack-ai-apps.html

- **Winning Strategies from HackAPrompt 2.0: Techniques and Tactics** — LinkedIn / writeup (community recap)  
  https://www.linkedin.com/pulse/winning-strategies-from-hackaprompt-20-techniques-tactics-al-anati-av6be/?trackingId=gpV1zFEdQmiiCGMZ%2FCakbQ%3D%3D

---

## Notes
- Prefer reputable vendor blogs, security research labs, and established practitioners.  
- Chronology chosen for quick scanning of fresh material. Add `YYYY-MM-DD` dates for entries you add in the future for precision.

