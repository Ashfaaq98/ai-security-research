[![Repo Status](https://img.shields.io/badge/status-active-brightgreen)](https://github.com/ashfaaq98/ai-security-research)
[![License](https://img.shields.io/github/license/ashfaaq98/ai-security-research)](LICENSE)
[![Last Updated](https://img.shields.io/github/last-commit/ashfaaq98/ai-security-research-hub)](https://github.com/ashfaaq98/ai-security-research/commits)
[![Made with â¤ï¸](https://img.shields.io/badge/made%20with-%E2%9D%A4-red)](https://github.com/ashfaaq98/ai-security-research)
[![Topics](https://img.shields.io/badge/focus-AI%20Security-blueviolet)](https://github.com/ashfaaq98/ai-security-research)

# AI Security Research Hub

A collection of resources documenting my research and learning journey in AI Security.
This repository holds resources related to my research and study journey in the field of AI Security.

Over time, Iâ€™ve been collecting a wide range of materials that I now aim to organize and maintain here. These include foundational and advanced resources that support my ongoing exploration of security challenges in artificial intelligence systems which includes llm models, ai agents and mcp servers.


---

## ğŸ“ Contents

### ğŸ“š Blogs  
Curated posts and personal notes on AI security topics, vulnerabilities, and real-world incidents.

[Blogs](./resources/BLOGS.md)


### ğŸ“„ Research Papers  
Key academic and industry papers covering adversarial ML, model inversion, data poisoning, secure model training, red teaming, and related areas.

[Research Papers](./resources/RESOURCES.md)


### ğŸ› ï¸ Tools  
A collection of open-source tools and frameworks useful for analysis, red teaming, and securing AI models. This includes mcp scanners.

[Red Teaming Tools](./resources/RESOURCES.md)

---


## ğŸ¤ Contributing

Contributions are welcome!  
If youâ€™d like to add a new tool, paper, or blog, please check out the [CONTRIBUTING.md](./CONTRIBUTING.md) file for guidelines on formatting and submission.
